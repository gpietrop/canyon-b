{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CANYON-MED \n",
    "Implementation following the instruction of the article *'A Regional Neural Network Approach to  estimate Water-COlumn Nutrient COncentrations and Carbonate System Variables in the Mediterranean Sea: CANYON-MED'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from blitz.modules import BayesianLinear\n",
    "from IPython import display\n",
    "from torchvision import datasets, transforms\n",
    "from res.plot_lib import plot_data, plot_model, set_default\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=4/3\n",
    "a=1.7159\n",
    "def mysigmoid(x):\n",
    "    return A*torch.sigmoid(x*a/2) #A*(np.exp(a*x) -1)/(np.exp(a*x)+1)\n",
    "\n",
    "class MySigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return mysigmoid(x)\n",
    "        \n",
    "activation_function = MySigmoid() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsigmoid(pre, lat, lon):\n",
    "    res=1/(1+np.exp((pre-prespivot(lat,lon))/50))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "presgrid=pd.read_csv(\"../dataset/CY_doy_pres_limit.csv\", \"\\t\").to_numpy()\n",
    "data=pd.read_csv(\"../dataset/data_CT.csv\")\n",
    "mont_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "\n",
    "dataset=data[data.categ=='training']          \n",
    "validation=data[data.categ=='validation']\n",
    "\n",
    "out_d=dataset['tcarbn'].to_numpy()\n",
    "in_d=dataset[['date','date', 'date','latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()\n",
    "\n",
    "out_v=validation['tcarbn'].to_numpy()\n",
    "in_v=validation[['date','date', 'date', 'latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixd(dataset):\n",
    "    for i in range(len(dataset[:,0])):\n",
    "        dataset[i,0] = int(dataset[i,0][7:11])\n",
    "        dataset[i,1] = mont_dict[dataset[i,1][3:6]]\n",
    "        dataset[i,2] = int(dataset[i,2][0:2])\n",
    "\n",
    "fixd(in_d)\n",
    "fixd(in_v)\n",
    "in_d=in_d.astype('float64')\n",
    "in_v=in_v.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(in_d)\n",
    "target = torch.from_numpy(out_d)\n",
    "data=data.float()\n",
    "target=target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpietrop/anaconda3/envs/blitz/lib/python3.6/site-packages/scipy/interpolate/_fitpack_impl.py:977: RuntimeWarning: No more knots can be added because the additional knot would\n",
      "coincide with an old one. Probable cause: s too small or too large\n",
      "a weight to an inaccurate data point. (fp>s)\n",
      "\tkx,ky=1,1 nx,ny=65,80 m=65884 fp=17529338.937876 s=0.000000\n",
      "  warnings.warn(RuntimeWarning(_iermess2[ierm][0] + _mess))\n"
     ]
    }
   ],
   "source": [
    "lat_pivot=np.linspace(-90.5, 90.5, 182)\n",
    "lon_pivot=np.linspace(-180.5, 180.5, 362)\n",
    "presgrid=presgrid[:, 1:]\n",
    "x,y=np.meshgrid(lat_pivot,lon_pivot)\n",
    "prespivot=interpolate.interp2d(x,y,presgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(data):\n",
    "    fsigmoi=[]\n",
    "    for i in range(len(data[:,0])):\n",
    "        if data[i,4]>180:\n",
    "            data[i,4]=data[i,4]-360                                                  #longitude\n",
    "        fsigmoi.append(fsigmoid(data[i,5], data[1,3], data[i,4]))\n",
    "    data[:,3]=data[:,3]/90                                                           #latitude [-90,90]/90\n",
    "    data[:,5]=(data[:,5]/20000) + (1 / ((1+np.exp(-(data[:,5])/300))**3))            #pressure\n",
    "    for i in range(len(data[:,0])):\n",
    "        day=data[i,2].item()\n",
    "        month=data[i,1]*30\n",
    "        month=month.item()\n",
    "        time=day+month\n",
    "        data[i,1]=np.cos(time*2*np.pi/365)*fsigmoi[i]\n",
    "        data[i,2]=np.sin(time*2*np.pi/365)*fsigmoi[i]\n",
    "    return data\n",
    "\n",
    "data=prep_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_fun_d(data):\n",
    "    mean=[ data[:,i].mean() for i in range(data.size()[1]) ]\n",
    "    std =[ data[:,i].std() for i in range(data.size()[1]) ]\n",
    "    for i in range(data.size()[1]):\n",
    "        data[:,i]=2/3*(data[:,i]-mean[i])/std[i] \n",
    "    return data, mean, std\n",
    "\n",
    "def norm_fun_t(target):\n",
    "    mean=target.mean()\n",
    "    std=target.std()\n",
    "    #target=2/3*(target-mean)/std\n",
    "    return mean, std #target, mean, std\n",
    "\n",
    "data, mean_data, std_data=norm_fun_d(data)\n",
    "#mean_ct, std_ct =norm_fun_t(target)\n",
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9 #input number\n",
    "best_topo_all=[[i,31,23,1],[i,20,8,1],[i,18,13,1],[i,35,21,1],[i,35,9,1],[i,36,21,1],[i,39,26,1],[i,44,27,1],[i,47,21,1],[i,47,29,1]]\n",
    "\n",
    "def top_select(best_topo_all, n):\n",
    "    best_topo=best_topo_all[0:n]\n",
    "    return best_topo  \n",
    "\n",
    "best_topo=top_select(best_topo_all,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Bayesian(nn.Module):\n",
    "    def __init__(self, top):\n",
    "        input_size, n_hidden1, n_hidden2, output_size = best_topo[top]\n",
    "        super( MLP_Bayesian , self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            BayesianLinear(input_size, n_hidden1), #nn.Linear(input_size, n_hidden1), #\n",
    "            activation_function, #nn.SELU(),  #  funzione bene con nn.ReLU(), ELU(),\n",
    "            BayesianLinear(n_hidden1, n_hidden2), #nn.Linear(n_hidden1, n_hidden2), #\n",
    "            activation_function, #nn.SELU(), #\n",
    "            BayesianLinear(n_hidden2, output_size), #nn.Linear(n_hidden2, output_size), #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "losses= [] \n",
    "def train(model, ep):\n",
    "    \n",
    "    for t in range(ep):\n",
    "        \n",
    "        output = model(data)\n",
    "        criterion=torch.nn.L1Loss()                                        #criterion=torch.nn.L1Loss()\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(f\"[MODEL]: {top+1}, [EPOCH]: {t}, [LOSS]: {loss.item():.6f}\")\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MODEL]: 1, [EPOCH]: 1008, [LOSS]: 1969.639893\n"
     ]
    }
   ],
   "source": [
    "models=list()\n",
    "models_loss=[]\n",
    "epoch=5000\n",
    "for top in range(len(best_topo)):\n",
    "    model_mlp=MLP_Bayesian(top)\n",
    "    models.append(model_mlp)\n",
    "    optimizer = optim.Adam(model_mlp.parameters(), lr=0.01)# , momentum=0.5)\n",
    "    train(model_mlp, epoch)\n",
    "    \n",
    "model=models[0]\n",
    "result=model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.resize_(4145, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sol1(sol,prev):\n",
    "    plt.plot(sol.detach().numpy(), 'ro', label='true solution')\n",
    "    plt.plot(prev.detach().numpy(), 'go', label='nn solution')\n",
    "    plt.ylabel('C_t')\n",
    "    plt.xlabel('samples')\n",
    "    plt.legend()\n",
    "\n",
    "plot_sol1(target, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sol2(sol,prev): \n",
    "    plt.scatter(sol.detach().numpy() ,prev.detach().numpy())\n",
    "    plt.plot(sol, sol)\n",
    "    plt.xlabel('C_t in situ')\n",
    "    plt.ylabel('C_t CANYON-MED')\n",
    "    \n",
    "plot_sol2(target, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(ep, losses):\n",
    "    ep_vect=[i for i in range(ep)]\n",
    "    plt.plot(ep_vect, losses, label= 'loss during epochs')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    \n",
    "error_plot(epoch, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR COMBINATION OF THE BEST 10 OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def ct_result(my_input):\n",
    "    outputs=[]\n",
    "    for top in range(len(best_topo)):\n",
    "        my_model=models[top]\n",
    "        my_output=my_model(my_input)\n",
    "        outputs.append(my_output)\n",
    "    out=sum(outputs)/len(outputs)\n",
    "    return out\n",
    "\n",
    "#out=ct_result(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
